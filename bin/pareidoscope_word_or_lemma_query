#!/usr/bin/python
# -*- coding: utf-8 -*-

import argparse
import collections
import itertools
import json
import logging
import multiprocessing
import operator
import os
import sqlite3

import networkx
from networkx.readwrite import json_graph
import numpy
import scipy.stats

from pareidoscope import star_extraction
from pareidoscope import subgraph_enumeration
from pareidoscope.utils import helper
from pareidoscope.utils import nx_graph
from pareidoscope.utils import statistics

logging.basicConfig(format="%(levelname)s %(asctime)s: %(message)s", level=logging.INFO)


def collect_frequencies(d, e, s, m, o11ids, r1ids, o11, r1, o11_to_r1):
    """"""
    # q1 = "SELECT ese.classid FROM edge_star_elements AS ese JOIN edge_stars AS es ON ese.elemid = es.starid WHERE es.subgraph=? AND es.center=?"
    # q2 = "SELECT sse.classid FROM skel_star_elements AS sse JOIN skel_stars AS ss ON sse.elemid = ss.starid WHERE ss.subgraph=? AND ss.center=?"
    # get_classid = lambda q, t: d.execute(q, t).fetchall()[0][0]
    q1 = "SELECT ese.classid, esc.isomorphisms_per_star FROM edge_star_elements AS ese JOIN edge_stars AS es ON ese.elemid = es.starid JOIN edge_star_classes AS esc ON ese.classid = esc.classid WHERE es.subgraph=? AND es.center=?"
    q2 = "SELECT sse.classid, ssc.isomorphisms_per_star FROM skel_star_elements AS sse JOIN skel_stars AS ss ON sse.elemid = ss.starid JOIN skel_star_classes AS ssc ON sse.classid = ssc.classid WHERE ss.subgraph=? AND ss.center=?"
    get_classid_and_iso_per_star = lambda q, t: d.execute(q, t).fetchall()[0]
    for o in e:
        if o not in o11ids:
            o11ids[o] = get_classid_and_iso_per_star(q1, o)
        classid = o11ids[o][0]
        o11["stars"][classid] += e[o]["star_freq"]
        o11["centers"][classid] += e[o]["center_freq"]
        o11["isomorphisms"][classid] += o11ids[o][1] * e[o]["star_freq"]
    for r in s:
        if r not in r1ids:
            r1ids[r] = get_classid_and_iso_per_star(q2, r)
        classid = r1ids[r][0]
        r1["stars"][classid] += s[r]["star_freq"]
        r1["centers"][classid] += s[r]["center_freq"]
        r1["isomorphisms"][classid] += r1ids[r][1] * s[r]["star_freq"]
    for o in m:
        oid = o11ids[o][0]
        rids = list(set([r1ids[r][0] for r in m[o]]))
        if len(rids) != 1:
            raise Exception("More than one skel_star for edge_star %s: %s" % (oid, ", ".join(rids)))
        if oid in o11_to_r1:
            if o11_to_r1[oid] != rids[0]:
                raise Exception("More than one skel_star for edge_star %s: %s" % (oid, ", ".join([o11_to_r1[oid], rids[0]])))
        else:
            o11_to_r1[oid] = rids[0]


def get_frequencies_from_db(c, o11, r1, c1, n, lemma, tag):
    """"""
    q1 = "SELECT isomorphisms_per_star, stars, star_centers FROM edge_star_classes WHERE classid=?"
    q2 = "SELECT isomorphisms_per_star, stars, star_centers FROM skel_star_classes WHERE classid=?"
    pos_or_wc = "wc" if lemma else "pos"
    q3 = "SELECT sum(xes.star_centers) FROM %s_edge_stars AS xes JOIN edge_star_elements AS ese ON xes.starid=ese.elemid WHERE ese.classid=? AND xes. %s=?" % (pos_or_wc, pos_or_wc)
    for o in o11["stars"]:
        isomorphisms_per_star, stars, star_centers = c.execute(q1, (o,)).fetchone()
        c1["stars"][o] += stars
        c1["centers"][o] += star_centers
        c1["isomorphisms"][o] += isomorphisms_per_star * stars
        c1["collostructional"][o] += c.execute(q3, (o, tag)).fetchall()[0][0]
    for r in r1["stars"]:
        isomorphisms_per_star, stars, star_centers = c.execute(q2, (r,)).fetchone()
        n["stars"][r] += stars
        n["centers"][r] += star_centers
        n["isomorphisms"][r] += isomorphisms_per_star * stars


def calculate_associations(o11, r1, c1, n, o11_to_r1, measure=statistics.log_likelihood):
    """"""
    associations = {}
    for count_method in o11.keys():
        for o11_star in o11[count_method]:
            if o11_star not in associations:
                associations[o11_star] = {}
            f_o11 = o11[count_method][o11_star]
            f_c1 = c1[count_method][o11_star]
            r1_star = o11_to_r1[o11_star]
            f_r1, f_n = None, None
            try:
                f_r1 = r1[count_method][r1_star]
                f_n = n[count_method][r1_star]
            except TypeError:
                f_r1 = r1[count_method]
                f_n = n[count_method]
            o, e = statistics.get_contingency_table(f_o11, f_r1, f_c1, f_n)
            associations[o11_star][count_method] = measure(o, e)
    return associations


def calculate_association_strengths_and_correlations(o11, r1, c1, n, o11_to_r1):
    """"""
    dice_associations = calculate_associations(o11, r1, c1, n, o11_to_r1, statistics.dice)
    tscore_associations = calculate_associations(o11, r1, c1, n, o11_to_r1, statistics.t_score)
    ll_associations = calculate_associations(o11, r1, c1, n, o11_to_r1, statistics.log_likelihood)
    if len(dice_associations) > 1:
        dice_correlations = scipy.stats.spearmanr([[v["collostructional"], v["centers"], v["stars"], v["isomorphisms"]] for v in dice_associations.itervalues()])[0]
        tscore_correlations = scipy.stats.spearmanr([[v["collostructional"], v["centers"], v["stars"], v["isomorphisms"]] for v in tscore_associations.itervalues()])[0]
        ll_correlations = scipy.stats.spearmanr([[v["collostructional"], v["centers"], v["stars"], v["isomorphisms"]] for v in ll_associations.itervalues()])[0]
    else:
        dice_correlations = numpy.ones((4,4))
        tscore_correlations = numpy.ones((4,4))
        ll_correlations = numpy.ones((4,4))
    return dice_associations, tscore_associations, ll_associations, dice_correlations, tscore_correlations, ll_correlations
    

def connect_to_results_db(filename):
    """"""
    conn = sqlite3.connect(filename)
    c = conn.cursor()
    c.execute("PRAGMA page_size=4096")
    c.execute("PRAGMA cache_size=100000")
    c.execute("CREATE TABLE IF NOT EXISTS forms (formid INTEGER PRIMARY KEY AUTOINCREMENT, form TEXT, tag TEXT, islemma BOOLEAN, UNIQUE (form, tag, islemma))")
    # c.execute("CREATE TABLE IF NOT EXISTS stars (starid INTEGER PRIMARY KEY, star TEXT, center INTEGER, UNIQUE (star, center))")
    # c.execute("CREATE TABLE IF NOT EXISTS associations (formid INTEGER, starid INTEGER, counting_method TEXT, dice REAL, t_score REAL, log_likelihood REAL, o11 INTEGER, r1 INTEGER, c1 INTEGER, n INTEGER, UNIQUE(formid, starid, counting_method), FOREIGN KEY (formid) REFERENCES forms, FOREIGN KEY (starid) REFERENCES stars")
    c.execute("CREATE TABLE IF NOT EXISTS associations (formid INTEGER, starid INTEGER, counting_method TEXT, dice REAL, t_score REAL, log_likelihood REAL, o11 INTEGER, r1 INTEGER, c1 INTEGER, n INTEGER, UNIQUE(formid, starid, counting_method), FOREIGN KEY (formid) REFERENCES forms)")
    c.execute("CREATE TABLE IF NOT EXISTS correlations (formid INTEGER, counting_method_1 TEXT, counting_method_2 TEXT, rho_dice REAL, rho_t_score REAL, rho_log_likelihood REAL, UNIQUE (formid, counting_method_1, counting_method_2), FOREIGN KEY (formid) REFERENCES forms)")
    return conn, c


def insert_results_into_database(db, form, tag, islemma, o11, r1, c1, n, o11_to_r1, dice_associations, tscore_associations, ll_associations, dice_correlations, tscore_correlations, ll_correlations):
    """"""
    results_db = os.path.splitext(db)[0] + "_results.db"
    conn, c = connect_to_results_db(results_db)
    c.execute("INSERT OR IGNORE INTO forms (form, tag, islemma) VALUES (?, ?, ?)", (form, tag, islemma))
    formid = c.execute("SELECT formid FROM forms WHERE form=? AND tag=? AND islemma=?", (form, tag, islemma)).fetchall()[0][0]
    # star method measure
    counting_methods = ["collostructional", "centers", "stars", "isomorphisms"]
    get_freq = lambda freq, cm, starid: freq[cm] if cm == "collostructional" else freq[cm][starid]
    association_tuples = ((formid, starid, counting_method, dice_associations[starid][counting_method], tscore_associations[starid][counting_method], ll_associations[starid][counting_method], o11[counting_method][starid], get_freq(r1, counting_method, o11_to_r1[starid]), c1[counting_method][starid], get_freq(n, counting_method, o11_to_r1[starid])) for starid in ll_associations.iterkeys() for counting_method in counting_methods)
    c.executemany("INSERT OR IGNORE INTO associations (formid, starid, counting_method, dice, t_score, log_likelihood, o11, r1, c1, n) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)", association_tuples)
    correlation_tuples = ((formid, cm1, cm2, dice_correlations[i][j], tscore_correlations[i][j], ll_correlations[i][j]) for i, cm1 in enumerate(counting_methods) for j, cm2 in enumerate(counting_methods))
    c.executemany("INSERT OR IGNORE INTO correlations (formid, counting_method_1, counting_method_2, rho_dice, rho_t_score, rho_log_likelihood) VALUES (?, ?, ?, ?, ?, ?)", correlation_tuples)
    conn.commit()
    conn.close()



if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Run a batch of queries against a corpus')
    parser.add_argument("--db", type=os.path.abspath, required=True, help="Corpus database")
    # parser.add_argument("-o", "--output", type=str, required=True, help="Output prefix")
    parser.add_argument("-l", "--lemma", action="store_true", help="FORM is a lemma and TAG is a word class")
    parser.add_argument("FORM", type=str, help="Word form or lemma")
    parser.add_argument("TAG", type=str, help="part-of-speech or word-class tag")
    args = parser.parse_args()
    
    groupsize = 50 * 10 * multiprocessing.cpu_count()
    pool = multiprocessing.Pool(processes = multiprocessing.cpu_count())
    
    logging.info("connect to database '%s'" % args.db)
    conn = sqlite3.connect(args.db)
    c = conn.cursor()
    c.execute("PRAGMA cache_size=100000")
    # conn.create_function("REGEXP", 2, database.regexp)
    
    logging.info("check for search term")
    form = "lemma" if args.lemma else "word"
    tag = "wc" if args.lemma else "pos"
    q = "SELECT tokens.sentid, sentences.graph, tokens.position FROM tokens INNER JOIN types ON types.typeid = tokens.typeid INNER JOIN sentences ON sentences.sentid = tokens.sentid WHERE %s=? AND %s=?" % (form, tag)
    q_r1 = "SELECT count(*) FROM tokens INNER JOIN types ON types.typeid = tokens.typeid WHERE %s=? AND %s=?" % (form, tag)
    q_n = "SELECT count(*) FROM tokens INNER JOIN types ON types.typeid = tokens.typeid WHERE %s=?" % tag
    t = (args.FORM, args.TAG)
    q_type = "SELECT typeid FROM types WHERE %s=? AND %s=?" % (form, tag)
    if len(c.execute(q_type, t).fetchall()) > 0:
        logging.info("collect stars")
        o11 = {"stars": collections.Counter(), "centers": collections.Counter(), "isomorphisms": collections.Counter()}
        o11["collostructional"] = o11["centers"]
        r1 = {"stars": collections.Counter(), "centers": collections.Counter(), "isomorphisms": collections.Counter(), "collostructional": 0}
        c1 = {"stars": collections.Counter(), "centers": collections.Counter(), "isomorphisms": collections.Counter(), "collostructional": collections.Counter()}
        n = {"stars": collections.Counter(), "centers": collections.Counter(), "isomorphisms": collections.Counter(), "collostructional": 0}
        o11_to_r1 = {}
        for occurrences in helper.grouper_nofill(groupsize, c.execute(q, t)):
            o11ids, r1ids = {}, {}
            d = conn.cursor()
            r = pool.imap_unordered(star_extraction.extract_stars_for_position, occurrences, 10)
            # r = map(star_extraction.extract_stars_for_position, occurrences)
            for sentid, e, s, m in r:
                collect_frequencies(d, e, s, m, o11ids, r1ids, o11, r1, o11_to_r1)
        logging.info("get frequencies from database")
        get_frequencies_from_db(c, o11, r1, c1, n, args.lemma, args.TAG)
        r1["collostructional"] = c.execute(q_r1, t).fetchall()[0][0]
        n["collostructional"] = c.execute(q_n, (args.TAG,)).fetchall()[0][0]
        logging.info("calculate association strengths and correlations")
        dice_associations, tscore_associations, ll_associations, dice_correlations, tscore_correlations, ll_correlations = calculate_association_strengths_and_correlations(o11, r1, c1, n, o11_to_r1)
        logging.info("insert results into database")
        insert_results_into_database(args.db, args.FORM, args.TAG, args.lemma, o11, r1, c1, n, o11_to_r1, dice_associations, tscore_associations, ll_associations, dice_correlations, tscore_correlations, ll_correlations)
    logging.info("done")
    # for star, assoc in sorted(associations.iteritems(), key=lambda t: t[1]["centers"]):
    #     print star, assoc


