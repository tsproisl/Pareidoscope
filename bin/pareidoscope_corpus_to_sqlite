#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import argparse
import itertools
import json
import logging
import os

from networkx.readwrite import json_graph

from pareidoscope.utils import conllu
from pareidoscope.utils import cwb
from pareidoscope.utils import database
from pareidoscope.utils import nx_graph

logging.basicConfig(format="%(levelname)s %(asctime)s: %(message)s", level=logging.INFO)


def arguments():
    """"""
    parser = argparse.ArgumentParser(description="Convert a corpus in CoNLL-U or CWB-treebank format into a corresponding SQLite database")
    parser.add_argument("--db", type=os.path.abspath, required=True, help="SQLite3 database for results")
    parser.add_argument("--no-id", action="store_true", help="Corpus has no unique sentence IDs, create them on the fly")
    parser.add_argument("-f", "--format", choices=["conllu", "cwb"], required=True, help="Input format of the corpus: CoNLL-U or CWB-treebank")
    parser.add_argument("CORPUS", type=argparse.FileType("r", encoding="utf-8"), help="The input corpus")
    args = parser.parse_args()
    return args


def sentence_to_graph(args):
    """"""
    (sentence, origid), corpus_format = args
    if corpus_format == "cwb":
        create_digraph = nx_graph.create_nx_digraph_from_cwb
    elif corpus_format == "conllu":
        create_digraph = nx_graph.create_nx_digraph_from_conllu
    gs = create_digraph(sentence, origid)
    sensible = nx_graph.is_sensible_graph(gs)
    graph = ""
    if sensible:
        graph = json.dumps(json_graph.node_link_data(gs), ensure_ascii=False, sort_keys=True)
    return gs, graph, origid, sensible


def main():
    """"""
    args = arguments()
    conn, c = database.create_db(args.db)
    if args.format == "cwb":
        sents = cwb.sentences_iter(args.CORPUS, return_id=True)
    elif args.format == "conllu":
        sents = conllu.sentences_iter(args.CORPUS, return_id=True)
    if args.no_id:
        sents = ((s, "s-%d" % i) for i, (s, _) in zip(itertools.count(1), sents))
    result = map(sentence_to_graph, zip(sents, itertools.repeat(args.format)))
    for gs, graph, origid, sensible in result:
        if sensible:
            database.insert_sentence(c, origid, gs, graph)
    conn.commit()
    conn.close()


if __name__ == "__main__":
    main()
