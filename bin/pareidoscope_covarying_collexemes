#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""generate all embeddings

an embedding is a tuple of vertex ids where the ids correspond to the
target indices and their indices to query indices

count embeddings: use embeddings directly

count subgraphs: two embeddings are the same subgraph if their sets
are identical

count focus points: two embeddings are counted only once if they have
the same value for the focus point vertex

count sentences: two embeddings are counted only once if they occur in
the same sentences

partition the embeddings

for every partition, increment counts for all instances of node,
collocate and their combinations

"""

import argparse
import collections

import pareidoscope.query
from pareidoscpe import subgraph_isomorphism
from pareidoscope.utils import database
from pareidoscope.utils import statistics
from pareidoscope.utils import nx_graph


def arguments():
    """"""
    parser = argparse.ArgumentParser(description="Perform a covarying collexeme analysis, i.e. find cooccurring words within a linguistic structure. If the structure is a single dependency relation, this is equivalent to relational cooccurrences.")
    parser.add_argument("-c", "--collexeme", choices=["word", "lemma"], default="lemma", help="Should we look for collexemes at the word level or at the lemma level? Default: lemma")
    parser.add_argument("-o", "--output", type=str, required=True, help="Output prefix")
    parser.add_argument("-p", "--cpu", type=int, default=25, help="Percentage of CPUs to use (0-100; default: 25)")
    parser.add_argument("CORPUS", type=os.path.abspath, help="Input corpus as SQLite3 database")
    parser.add_argument("QUERIES", type=argparse.FileType("r", encoding="utf-8"), help="Queries file as JSON list")
    return parser.parse_args()


def identify_collo_items(graph):
    """Search for collo_A and collo_B"""
    collo_a, collo_b, focus_point = None, None, None
    for v, l in graph.nodes(data=True):
        if "collo_A" in l:
            collo_a = v
            del l["collo_A"]
        if "collo_B" in l:
            collo_b = v
            del l["collo_B"]
        if "focus_point" in l:
            focus_point = v
            del l["focus_point"]
    if focus_point is None:
        focus_point = nx_graph.get_choke_point(graph)
    assert collo_a is not None and collo_b is not None and focus_point is not None
    return graph, focus_point, collo_a, collo_b


def get_cooccurrences(args):
    """"""
    query_graph, target_graph, focus_point, collo_a, collo_b, word_or_lemma = args
    embeddings = collections.defaultdict(set)
    subgraphs = collections.defaultdict(set)
    focus_points = collections.defaultdict(set)
    sentences = collections.defaultdict(set)
    target_graph = json_graph.node_link_graph(json.loads(target_graph))
    isomorphisms = subgraph_isomorphism.get_subgraph_isomorphisms_nx(query_graph, target_graph)
    for iso in isomorphisms:
        item_a = target_graph.node[iso[collo_a]][word_or_lemma]
        item_b = target_graph.node[iso[collo_b]][word_or_lemma]
        pair = (item_a, item_b)
        embeddings(iso).add(pair)
        subgraphs[tuple(sorted(iso))].add(pair)
        focus_points[iso[focus_point]].add(pair)
    

def main():
    """"""
    args = arguments()
    conn, c = database.connect_to_database(args.CORPUS)
    queries = pareidoscope.query.read_queries(args.QUERIES)
    results = []
    cpu_count = multiprocessing.cpu_count()
    processes = min(max(1, int(cpu_count * args.cpu / 100)), cpu_count)
    with multiprocessing.Pool(processes=processes) as pool:
        for i, query in enumerate(queries):
            logging.info("query no. %d" % i)
            graph, focus_point, collo_a, collo_b = identify_collo_items(query)
            with tempfile.TemporaryFile() as fp:
                sents = database.sentence_candidates(c, pareidoscope.query.strip_vid(graph))
                for s in sents:
                    fp.write((s + "\n").encode(encoding="utf-8"))
                fp.seek(0)
                sentences = (s.decode(encoding="utf-8").rstrip() for s in fp)

if __name__ == "__main__":
    main()
