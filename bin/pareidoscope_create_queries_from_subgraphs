#!/usr/bin/python
# -*- coding: utf-8 -*-

import argparse
import collections
import itertools
import json
import operator
import os
import random
import sys

import networkx
from networkx.readwrite import json_graph

from pareidoscope.utils import nx_graph
from pareidoscope.utils import random_trees
from pareidoscope.utils import cwb


def underspecify(graph, probability):
    """Underspecify vertices and edges with a certain probability.

    Args:
      graph: 
      probability:

    """
    for v in graph.nodes():
        if random.random() < probability:
            graph.node[v]["word"] = ".+"
            graph.node[v]["pos"] = ".+"
            graph.node[v]["lemma"] = ".+"
            graph.node[v]["wc"] = ".+"
    for s, t in graph.edges():
        if random.random() < probability:
            graph.edge[s][t]["relation"] = ".+"


def split_graph(graph):
    """Split graph into two subgraphs and return queries.

    Args:
      graph:

    """
    both_connected = False
    all_vertices = graph.nodes()
    all_vertices_set = set(all_vertices)
    nr_of_vertices = random.randint(1, graph.__len__()-1)
    a, b = None, None
    while not both_connected:
        random.shuffle(all_vertices)
        a_vertices = set(all_vertices[0:nr_of_vertices])
        b_vertices = all_vertices_set - a_vertices
        a = graph.subgraph(a_vertices)
        b = graph.subgraph(b_vertices)
        both_connected = networkx.is_weakly_connected(a) and networkx.is_weakly_connected(b)
    for s, t, l in graph.edges(data=True):
        if (not a.has_edge(s, t)) and (not b.has_edge(s, t)):
            if random.choice(["a", "b"]) == "a":
                a.add_node(t, {"word": ".+", "pos": ".+", "lemma": ".+", "wc": ".+"})
                a.add_edge(s, t, l)
            else:
                b.add_node(t, {"word": ".+", "pos": ".+", "lemma": ".+", "wc": ".+"})
                b.add_edge(s, t, l)
    n = graph.copy()
    for vertice in n.nodes():
        n.node[vertice]["word"] = ".+"
        n.node[vertice]["pos"] = ".+"
        n.node[vertice]["lemma"] = ".+"
        n.node[vertice]["wc"] = ".+"
    for s, t in n.edges():
        n.edge[s][t]["relation"] = ".+"
    r1 = n.copy()
    for vertice in a.nodes():
        r1.node[vertice] = a.node[vertice]
    for s, t in a.edges():
        r1.edge[s][t]["relation"] = a.edge[s][t]["relation"]
    c1 = n.copy()
    for vertice in b.nodes():
        c1.node[vertice] = b.node[vertice]
    for s, t in b.edges():
        c1.edge[s][t]["relation"] = b.edge[s][t]["relation"]
    return a, b, r1, c1, n



if __name__ == "__main__":
    description = "Create queries based on frequent subgraphs (extracted with pareidoscope_frequent_subgraphs)."
    parser = argparse.ArgumentParser(description=description)
    parser.add_argument("--underspec", help="Probability for a vertice or edge to be underspecified, i.e. to be labeled '.+'; default: 0.0", type=float, default=0.0, metavar="R")
    parser.add_argument("-o", "--outfile", type=argparse.FileType("w"), required=True, help="Output file")
    parser.add_argument("SUBGRAPHS", type=argparse.FileType("r"), help="Frequent subgraphs file (JSON)")
    args = parser.parse_args()
    
    subgraphs = json.load(args.SUBGRAPHS)
    for subgraph in subgraphs:
        sg = json_graph.node_link_graph(json.loads(subgraph))
        underspecify(sg, args.underspec)
        a, b, r1, c1, n = split_graph(sg)
        args.outfile.write("\t".join([json.dumps(nx_graph.export_to_adjacency_matrix(x)) for x in [sg, a, b, r1, c1, n]]) + "\n")
